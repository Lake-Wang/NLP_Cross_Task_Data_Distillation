{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-08T04:44:43.018981Z",
     "start_time": "2024-12-08T04:44:42.877875Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d3cb15562794e4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load tokenizer and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "324db4b2bb2a08a8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T04:44:45.086236Z",
     "start_time": "2024-12-08T04:44:42.931393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Photos Plus Music Equals an Expensive iPod (washingtonpost.com) washingtonpost.com - First Apple put some color on the iPod, when it offered the iPod mini in a palette of pastel hues, and now it has put some color inside it, in the form of the new iPod Photo.', 'label': 3}\n",
      "{'sentence': \"it 's a charming and often affecting journey . \", 'label': 1, 'idx': 0}\n"
     ]
    }
   ],
   "source": [
    "TASK_ATTRS = {\n",
    "    \"ag_news\": {\"load_args\": (\"ag_news\",), \"sent_keys\": (\"text\",), 'split':'test'},\n",
    "    \"sst2\": {\"load_args\": (\"glue\", \"sst2\"), \"sent_keys\": (\"sentence\",), 'split':'validation'},\n",
    "    \"qnli\": {\"load_args\": (\"glue\", \"qnli\"), \"sent_keys\": (\"question\", \"sentence\"), 'split':'validation'},\n",
    "    \"mrpc\": {\"load_args\": (\"glue\", \"mrpc\"), \"sent_keys\": (\"sentence1\", \"sentence2\"), 'split':'test'},\n",
    "}\n",
    "\n",
    "TASK=\"ag_news\"  # select from (\"ag_news\", \"mrpc\", \"qnli\", \"sst2\")\n",
    "\n",
    "load_args = TASK_ATTRS[TASK][\"load_args\"]\n",
    "sent_keys = TASK_ATTRS[TASK][\"sent_keys\"]\n",
    "split = TASK_ATTRS[TASK][\"split\"]\n",
    "\n",
    "dataset1 = load_dataset(*load_args, split=split)\n",
    "sample_size = int(0.1 * len(dataset1))\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Sample 10% of the dataset\n",
    "dataset1 = dataset1.select(random.sample(range(len(dataset1)), sample_size))\n",
    "\n",
    "print(dataset1[0])\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "dataset1 = dataset1.map(\n",
    "    lambda ex: tokenizer(\n",
    "        *(ex[k] for k in sent_keys), max_length=tokenizer.model_max_length, truncation=True\n",
    "    ),\n",
    "    batched=True,\n",
    ")\n",
    "if \"label\" in dataset1.column_names:\n",
    "    dataset1 = dataset1.rename_column(\"label\", \"labels\")\n",
    "\n",
    "remove_keys = [\n",
    "    name for name in  dataset1.column_names\n",
    "    if name not in ['labels', 'input_ids', 'token_type_ids', 'attention_mask']\n",
    "]\n",
    "dataset1 = dataset1.remove_columns(remove_keys)\n",
    "\n",
    "TASK=\"sst2\"  # select from (\"ag_news\", \"mrpc\", \"qnli\", \"sst2\")\n",
    "\n",
    "load_args = TASK_ATTRS[TASK][\"load_args\"]\n",
    "sent_keys = TASK_ATTRS[TASK][\"sent_keys\"]\n",
    "split = TASK_ATTRS[TASK][\"split\"]\n",
    "\n",
    "dataset2 = load_dataset(*load_args, split=split)\n",
    "\n",
    "print(dataset2[0])\n",
    "\n",
    "\n",
    "dataset2 = dataset2.map(\n",
    "    lambda ex: tokenizer(\n",
    "        *(ex[k] for k in sent_keys), max_length=tokenizer.model_max_length, truncation=True\n",
    "    ),\n",
    "    batched=True,\n",
    ")\n",
    "if \"label\" in dataset2.column_names:\n",
    "    dataset2 = dataset2.rename_column(\"label\", \"labels\")\n",
    "\n",
    "remove_keys = [\n",
    "    name for name in  dataset2.column_names\n",
    "    if name not in ['labels', 'input_ids', 'token_type_ids', 'attention_mask']\n",
    "]\n",
    "dataset2 = dataset2.remove_columns(remove_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7c3f62e6572459ea",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T04:44:45.092027Z",
     "start_time": "2024-12-08T04:44:45.088690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 760\n})"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 872\n})"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T04:44:45.096154Z",
     "start_time": "2024-12-08T04:44:45.093554Z"
    }
   },
   "id": "cbc9f5ed1b2e0ae3"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a72f675a008d8efc",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T04:44:45.164886Z",
     "start_time": "2024-12-08T04:44:45.097396Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "collate_fn = DataCollatorWithPadding(\n",
    "    tokenizer=tokenizer, padding=\"longest\", pad_to_multiple_of=8\n",
    ")\n",
    "test_loader_task1 = DataLoader(\n",
    "    dataset1, batch_size=256, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "test_loader_task2 = DataLoader(\n",
    "    dataset2, batch_size=256, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dc94dcc4307127",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load distilled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7ffe647bd6e6975c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T04:44:45.196896Z",
     "start_time": "2024-12-08T04:44:45.169585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1.0\n",
      "{'inputs_embeds': torch.Size([4, 512, 768]), 'labels': torch.Size([4, 4]), 'attention_labels': torch.Size([4, 12, 12, 1, 512]), 'lr': torch.Size([1])}\n",
      "{'inputs_embeds': torch.Size([2, 512, 768]), 'labels': torch.Size([2, 2]), 'attention_labels': torch.Size([2, 12, 12, 1, 512]), 'lr': torch.Size([1])}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "task1, task2 = 'ag_news', 'sst2'\n",
    "\n",
    "#data_path = f\"distilled_data_examples/{TASK}/1_shot-1_step-1_epoch-soft_label-cls_al\"\n",
    "#data_path_1 = r\"C:\\Users\\alber\\OneDrive\\dataset-distillation-with-attention-labels\\distilled_data_examples\\{task1}\\test\"\n",
    "#data_path_2 = r\"C:\\Users\\alber\\OneDrive\\dataset-distillation-with-attention-labels\\distilled_data_examples\\{task2}\\test\"\n",
    "data_path_1 = os.path.normpath(os.path.join(\"../distilled_data_examples/data\", task1, \"test\"))\n",
    "data_path_2 = os.path.normpath(os.path.join(\"../distilled_data_examples/data\", task2, \"test\"))\n",
    "#data_path_2 = os.path.join(\"..\", \"distilled_data_examples\", task2, \"test\")\n",
    "#data_path = f\"../distilled_data_examples/ag_sst2_with_sst2_label\"\n",
    "\n",
    "config_1 = json.load(open(os.path.join(data_path_1, \"config.json\")))\n",
    "task1_data = torch.load(os.path.join(data_path_1, \"data_dict\"))\n",
    "config_2 = json.load(open(os.path.join(data_path_2, \"config.json\")))\n",
    "task2_data = torch.load(os.path.join(data_path_2, \"data_dict\"))\n",
    "\n",
    "\n",
    "print(config_1[\"train_config\"][\"train_step\"])\n",
    "train_step = config_1[\"train_config\"][\"train_step\"]\n",
    "batch_size_per_label = config_1[\"train_config\"][\"batch_size_per_label\"]\n",
    "num_labels = config_2[\"num_labels\"]\n",
    "batch_size = batch_size_per_label * num_labels\n",
    "attn_lambda = config_1[\"config\"][\"attention_loss_lambda\"]\n",
    "\n",
    "print(train_step)\n",
    "print(batch_size_per_label)\n",
    "print(num_labels)\n",
    "print(attn_lambda)\n",
    "\n",
    "print({k: v.shape for k, v in task1_data.items()})\n",
    "print({k: v.shape for k, v in task2_data.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769f2c3c794db285",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Dataset and Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3274b412f28441e0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T04:44:45.235191Z",
     "start_time": "2024-12-08T04:44:45.195947Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiTaskDataset(Dataset):\n",
    "    def __init__(self, task1_data, task1_labels, task1_attention_labels, task2_data, task2_labels,\n",
    "                 task2_attention_labels):\n",
    "        self.inputs = torch.cat([task1_data, task2_data], dim=0)\n",
    "\n",
    "        # Determine the maximum label dimension\n",
    "        max_label_dim = max(task1_labels.size(1), task2_labels.size(1))\n",
    "\n",
    "        # Pad task1_labels and task2_labels to the same size\n",
    "        self.task1_label_dim = task1_labels.size(1)\n",
    "        self.task2_label_dim = task2_labels.size(1)\n",
    "\n",
    "        task1_labels = torch.nn.functional.pad(task1_labels, (0, max_label_dim - task1_labels.size(1)))\n",
    "        task2_labels = torch.nn.functional.pad(task2_labels, (0, max_label_dim - task2_labels.size(1)))\n",
    "\n",
    "        # Combine classification labels\n",
    "        self.labels = torch.cat([task1_labels, task2_labels], dim=0)\n",
    "\n",
    "        # Combine attention labels\n",
    "        self.attention_labels = torch.cat([task1_attention_labels, task2_attention_labels], dim=0)\n",
    "\n",
    "        # Task identifiers (0 for Task 1, 1 for Task 2)\n",
    "        self.task_ids = torch.cat([\n",
    "            torch.zeros(task1_data.size(0), dtype=torch.long),  # Task 1 identifier\n",
    "            torch.ones(task2_data.size(0), dtype=torch.long)   # Task 2 identifier\n",
    "        ])\n",
    "\n",
    "        # Store the split point to distinguish between tasks\n",
    "        self.task1_size = task1_data.size(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.inputs.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, (list, torch.Tensor)):  # If idx is a list or tensor, handle batch mode\n",
    "            return [self.__getitem__(i) for i in idx]\n",
    "        \n",
    "        inputs = self.inputs[idx]\n",
    "        labels = self.labels[idx]\n",
    "        attention_labels = self.attention_labels[idx]\n",
    "        task_id = self.task_ids[idx]\n",
    "    \n",
    "        # Adjust labels based on the task\n",
    "        if task_id == 0:  # Task 1\n",
    "            labels = labels[:self.task1_label_dim]\n",
    "        else:  # Task 2\n",
    "            labels = labels[:self.task2_label_dim]\n",
    "        \n",
    "        return inputs, labels, attention_labels, task_id\n",
    "\n",
    "task1_embeds = task1_data['inputs_embeds']\n",
    "task1_labels = task1_data['labels']\n",
    "task1_attention_labels = task1_data['attention_labels']\n",
    "task1_lr = task1_data['lr']\n",
    "\n",
    "task2_embeds = task2_data['inputs_embeds']\n",
    "task2_labels = task2_data['labels']\n",
    "task2_attention_labels = task2_data['attention_labels']\n",
    "task2_lr = task2_data['lr']\n",
    "\n",
    "# Dataset and DataLoader\n",
    "dataset = MultiTaskDataset(task1_embeds, task1_labels, task1_attention_labels,\n",
    "                           task2_embeds, task2_labels, task2_attention_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "41c8873ba1d0107c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T04:44:45.239454Z",
     "start_time": "2024-12-08T04:44:45.226061Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, encoder, num_classes_task1=4, num_classes_task2=2, num_layers_to_freeze=4):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        self.encoder = encoder\n",
    "\n",
    "        # Freeze specified number of encoder layers\n",
    "        print(f\"Freezing the first {num_layers_to_freeze} layers of the encoder...\")\n",
    "        for i in range(num_layers_to_freeze):\n",
    "            for param in self.encoder.encoder.layer[i].parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # Task-specific classifiers\n",
    "        task1_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"bert-base-uncased\", num_labels=num_classes_task1\n",
    "        )\n",
    "        task2_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"bert-base-uncased\", num_labels=num_classes_task2\n",
    "        )\n",
    "\n",
    "        # Use their classifier layers\n",
    "        self.task1_classifier = task1_model.classifier\n",
    "        self.task2_classifier = task2_model.classifier\n",
    "\n",
    "    def forward(self, inputs_embeds=None, input_ids=None, token_type_ids=None, task_id=None, attention_mask=None):\n",
    "        # Convert input_ids to inputs_embeds if input_ids is provided\n",
    "        if input_ids is not None:\n",
    "            inputs_embeds = self.encoder.embeddings(input_ids=input_ids, token_type_ids=token_type_ids)\n",
    "\n",
    "        if inputs_embeds is None:\n",
    "            raise ValueError(\"Either inputs_embeds or input_ids must be provided.\")\n",
    "\n",
    "        # Forward pass through the encoder\n",
    "        encoder_outputs = self.encoder(\n",
    "            inputs_embeds=inputs_embeds, attention_mask=attention_mask, output_attentions=True\n",
    "        )\n",
    "\n",
    "        # Shared representation from the encoder (CLS token output)\n",
    "        shared_representation = encoder_outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "        # Task-specific output\n",
    "        if task_id == None:\n",
    "            logits = self.task2_classifier(shared_representation)\n",
    "        elif task_id[0] == 0:\n",
    "            logits = self.task1_classifier(shared_representation)\n",
    "        elif task_id[0] == 1:  # Task 2\n",
    "            logits = self.task2_classifier(shared_representation)\n",
    "\n",
    "        # Use attentions from the encoder if needed\n",
    "        attentions = encoder_outputs.attentions\n",
    "\n",
    "        return logits, attentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ce52384383eaf2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5b7c6e7717ee170b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T04:44:45.239576Z",
     "start_time": "2024-12-08T04:44:45.227645Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import SGD\n",
    "\n",
    "def compute_task_loss(logits, labels, num_labels):\n",
    "    #print(logits.shape)\n",
    "    #print(labels.shape)\n",
    "    loss_task = F.cross_entropy(\n",
    "        logits.view(-1, num_labels), labels, reduction=\"none\"\n",
    "    )\n",
    "    return loss_task.mean()\n",
    "\n",
    "def compute_attn_loss(attentions, attention_labels):\n",
    "    #attention_labels = attention_labels.unsqueeze(0)\n",
    "    if attention_labels is not None:\n",
    "        attn_weights = torch.stack(attentions, dim=1)\n",
    "        attn_weights = attn_weights[..., : attention_labels.size(-2), :]\n",
    "        assert attn_weights.shape == attention_labels.shape\n",
    "        \n",
    "        #attn_weights = attn_weights / attn_weights.sum(dim=-1, keepdim=True)\n",
    "        #attention_labels = attention_labels / attention_labels.sum(dim=-1, keepdim=True)\n",
    "        \n",
    "        # Clamp attn_weights to avoid log(0)\n",
    "        #attn_weights = torch.clamp(attn_weights, min=1e-12)\n",
    "        #attention_labels = torch.clamp(attention_labels, min=1e-12)\n",
    "    \n",
    "        # Calculate KL divergence\n",
    "        attn_loss = F.kl_div(\n",
    "            torch.log(attn_weights),\n",
    "            attention_labels,\n",
    "            reduction=\"none\",\n",
    "        )\n",
    "    \n",
    "        return attn_loss.sum(-1).mean()\n",
    "\n",
    "    return 0.0\n",
    "\n",
    "def train_multitask(model, dataset, optimizer, batch_size, train_step, attn_lambda):\n",
    "    \"\"\"\n",
    "    Train function for multitask model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: MultiTaskModel instance.\n",
    "    - dataset: MultiTaskDataset instance containing inputs, labels, and attention labels.\n",
    "    - optimizer: Optimizer for the model.\n",
    "    - batch_size: Batch size for training.\n",
    "    - train_step: Total training steps.\n",
    "    - attn_lambda: Weight for the attention loss.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    #optimizer = SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=1.0)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    for step in range(train_step):\n",
    "        sample_len = len(dataset)\n",
    "        batch_start = step * batch_size % sample_len\n",
    "        batch_end = min(batch_start + batch_size, sample_len)\n",
    "        batch_indices = list(range(batch_start, batch_end))  # Generate indices as a list\n",
    "        \n",
    "        # Retrieve batch\n",
    "        batch = dataset[batch_indices]\n",
    "\n",
    "        # Use zip to group components by type\n",
    "        inputs, labels, attention_labels, task_ids = zip(*batch)\n",
    "        \n",
    "\n",
    "        # Convert to tensors if needed\n",
    "        inputs_embeds = torch.stack(inputs)               # Stack inputs (if tensors)\n",
    "        inputs_embeds = inputs_embeds.to(device)\n",
    "        labels = torch.stack(labels)                 # Concatenate labels (if tensors)\n",
    "        attention_labels = torch.stack(attention_labels)  # Concatenate attention labels (if tensors)\n",
    "        task_ids = torch.tensor(task_ids)          # Convert task IDs to tensor\n",
    "        task_ids = task_ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "        attention_labels = attention_labels.to(device)\n",
    "        lr = task1_lr if task_ids[0] == 0 else task2_lr\n",
    "        lr = F.softplus(lr).item()\n",
    "        attention_labels = F.softmax(attention_labels, dim=-1)\n",
    "\n",
    "        # Forward pass for the entire batch\n",
    "        logits, attentions = model(inputs_embeds=inputs_embeds, task_id=task_ids)\n",
    "\n",
    "        # Task-specific loss\n",
    "        loss_task = compute_task_loss(logits, labels, num_labels=logits.shape[1])\n",
    "\n",
    "        # Attention loss\n",
    "        loss_attn = compute_attn_loss(attentions, attention_labels)\n",
    "        #loss_attn = 0\n",
    "\n",
    "        # Combined loss\n",
    "        loss = loss_task + attn_lambda * loss_attn\n",
    "        loss *= lr\n",
    "        \n",
    "        # print('normal loss: ', loss_task)\n",
    "        # print('attention loss: ', loss_attn)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Step {step + 1}/{train_step}, Task{task_ids[0]}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Training completed in {elapsed:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1de503a4001a5baf",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T04:44:45.240190Z",
     "start_time": "2024-12-08T04:44:45.237377Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def evaluate_model(model, test_loader, task_id):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    total_loss, num_samples = 0, 0\n",
    "    for batch in tqdm(test_loader, desc=\"Evaluating model\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        labels = batch.pop(\"labels\")\n",
    "        #print(labels)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits, attention = model(**batch, task_id=task_id)\n",
    "            loss = compute_task_loss(logits, labels, num_labels=logits.shape[1])\n",
    "\n",
    "        metric.add_batch(\n",
    "            predictions=logits.argmax(-1).tolist(),\n",
    "            references=labels.tolist()\n",
    "        )\n",
    "        total_loss += loss.item() * len(labels)\n",
    "        num_samples += len(labels)\n",
    "        \n",
    "        print(f'Task {task_id} evaluation loss: {loss.item()}')\n",
    "\n",
    "    results = metric.compute()\n",
    "    results[\"loss\"] = total_loss / num_samples\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "713bd0c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T04:44:45.638226Z",
     "start_time": "2024-12-08T04:44:45.241854Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\r\n",
      "      - Validating: \u001B[32mOK\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "081b6dea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T04:44:45.645281Z",
     "start_time": "2024-12-08T04:44:45.640392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "IntSlider(value=0)",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e45ba0153f2444ba19055dce90e5725"
      }
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "widgets.IntSlider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "943d0fca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T04:44:45.647872Z",
     "start_time": "2024-12-08T04:44:45.645699Z"
    }
   },
   "outputs": [],
   "source": [
    "def move_state_dict_to_device(state_dict, device):\n",
    "    return {key: value.to(device) for key, value in state_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "547e982fe8c9e1a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T04:47:56.938914Z",
     "start_time": "2024-12-08T04:44:45.653309Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing the first 0 layers of the encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of encoder layers: 12\n",
      "Freezing the first 3 layers of the encoder...\n",
      "Freezing the first 3 layers of the encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Evaluating model:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fbb7d1fc5f9a442f88cc48ce5923805d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task [0] evaluation loss: 1.4355992078781128\n",
      "Task [0] evaluation loss: 1.4456617832183838\n",
      "Task [0] evaluation loss: 1.4114227294921875\n",
      "----------------------------------------\n",
      "AG Before training: {'accuracy': 0.225, 'loss': 1.4310995403089022}\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "Evaluating model:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2a79a881e3b4397931a18ded0947933"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task [1] evaluation loss: 0.732970654964447\n",
      "Task [1] evaluation loss: 0.7354337573051453\n",
      "Task [1] evaluation loss: 0.7158809900283813\n",
      "Task [1] evaluation loss: 0.7278229594230652\n",
      "----------------------------------------\n",
      "SST Before training: {'accuracy': 0.4369266055045872, 'loss': 0.7280626728994037}\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Step 1/6, Task0, Loss: 1.0087\n",
      "Step 2/6, Task0, Loss: 0.6036\n",
      "Step 3/6, Task1, Loss: 0.1274\n",
      "Step 4/6, Task0, Loss: 0.0162\n",
      "Step 5/6, Task0, Loss: 0.2838\n",
      "Step 6/6, Task1, Loss: 0.0797\n",
      "Training completed in 13.61s\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "Evaluating model:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5660f47b9e9b4f39955bd63e580653ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task [0] evaluation loss: 1.5628390312194824\n",
      "Task [0] evaluation loss: 1.473114252090454\n",
      "Task [0] evaluation loss: 1.4652178287506104\n",
      "----------------------------------------\n",
      "AG After training: {'accuracy': 0.3263157894736842, 'loss': 1.5007606079703883}\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "Evaluating model:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8bc829e435e9477baa1fc7f46be42672"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task [1] evaluation loss: 0.7112665176391602\n",
      "Task [1] evaluation loss: 0.6918203234672546\n",
      "Task [1] evaluation loss: 0.722996711730957\n",
      "Task [1] evaluation loss: 0.7092440128326416\n",
      "----------------------------------------\n",
      "SST After training: {'accuracy': 0.5034403669724771, 'loss': 0.7087600537396352}\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, BertModel\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# load model\n",
    "encoder = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "model_base = MultiTaskModel(encoder, num_classes_task1=4, num_classes_task2=2, num_layers_to_freeze=0)\n",
    "encoder.load_state_dict(torch.load(\"encoder_trained.pth\"), strict=False)\n",
    "print(\"Length of encoder layers:\", len(encoder.encoder.layer))\n",
    "\n",
    "# Define the number of layers to freeze\n",
    "num_layers_to_freeze = 3\n",
    "model = MultiTaskModel(encoder, num_classes_task1=4, num_classes_task2=2, num_layers_to_freeze=num_layers_to_freeze)\n",
    "model_original = MultiTaskModel(encoder, num_classes_task1=4, num_classes_task2=2, num_layers_to_freeze=num_layers_to_freeze)\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "\n",
    "# Evaluate bofore training\n",
    "results = evaluate_model(model_base, test_loader_task1, task_id=[0])\n",
    "print(\"-\"*40)\n",
    "print(\"AG Before training:\", results)\n",
    "print(\"-\"*40)\n",
    "results = evaluate_model(model_base, test_loader_task2, task_id=[1])\n",
    "print(\"-\"*40)\n",
    "print(\"SST Before training:\", results)\n",
    "print(\"-\"*40)\n",
    "\n",
    "# Train model\n",
    "print(\"-\"*40)\n",
    "train_multitask(model, dataset, optimizer, batch_size=2, train_step=6, attn_lambda=1.5)\n",
    "print(\"-\"*40)\n",
    "\n",
    "trained_state_dict = model.state_dict()\n",
    "original_state_dict = model_original.state_dict()\n",
    "original_state_dict = move_state_dict_to_device(original_state_dict, device)\n",
    "combined_state_dict = {}\n",
    "lambda_coef = 0.8\n",
    "\n",
    "for key in original_state_dict:\n",
    "    combined_state_dict[key] = (1-lambda_coef)*original_state_dict[key] + lambda_coef*trained_state_dict[key]\n",
    "#combined_state_dict.to(device)\n",
    "\n",
    "model.load_state_dict(combined_state_dict)\n",
    "\n",
    "\n",
    "# Evaluate after training\n",
    "results = evaluate_model(model, test_loader_task1, task_id=[0])\n",
    "print(\"-\"*40)\n",
    "print(\"AG After training:\", results)\n",
    "print(\"-\"*40)\n",
    "results = evaluate_model(model, test_loader_task2, task_id=[1])\n",
    "print(\"-\"*40)\n",
    "print(\"SST After training:\", results)\n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6f5260c9f479fa9d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T04:47:56.951786Z",
     "start_time": "2024-12-08T04:47:56.948753Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attention-labels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
